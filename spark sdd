spark学习内容
##spark sdd
####学习spark项目 spark rdd,两种操作，一种转化，一种行动
--个人理解rdd转化并不会产生计算，只是文件读取等等，而行动操作才是真正的计算.
创建rdd
```python  lines = sc.parallelize(["pandas", "i like pandas"])

转化操作返回的是RDD,而行动操作返回的是其它的数据类型,转化是惰性的，元素只会加载一次

表3-2：对一个数据为{1, 2, 3, 3}的RDD进行基本的RDD转化操作
函数名 目的 示例 结果
map() 将函数应用于 RDD 中的每个元
素，将返回值构成新的 RDD
rdd.map(x => x + 1) {2, 3, 4, 4}
flatMap() 将函数应用于 RDD 中的每个元
素，将返回的迭代器的所有内
容构成新的 RDD。通常用来切
分单词
rdd.flatMap(x => x.to(3)) {1, 2, 3, 2, 3, 3, 3}
filter() 返回一个由通过传给 filter()
的函数的元素组成的 RDD
rdd.filter(x => x != 1) {2, 3, 3}
distinct() 去重 rdd.distinct() {1, 2, 3}
sample(withRe
placement, fra
ction, [seed])
对 RDD 采样，以及是否替换 rdd.sample(false, 0.5) 非确定的
表3-3：对数据分别为{1, 2, 3}和{3, 4, 5}的RDD进行针对两个RDD的转化操作
函数名 目的 示例 结果
union() 生成一个包含两个 RDD 中所有元
素的 RDD
rdd.union(other) {1, 2, 3, 3, 4, 5}
intersection() 求两个 RDD 共同的元素的 RDD rdd.intersection(other) {3}
subtract() 移除一个 RDD 中的内容（例如移
除训练数据）
rdd.subtract(other) {1, 2}
cartesian() 与另一个 RDD 的笛卡儿积 rdd.cartesian(other) {(1, 3), (1, 4), ...
(3, 5)}
